
##  Ծրագրի Նկարագրություն

Այս նախագիծը իրականացված է `Spam Detection` խնդիր լուծելու նպատակով՝ օգտագործելով **TF-IDF** վեկտորիզացիա և **Լոգիստիկ ռեգրեսիա (Logistic Regression)**։  
Ծրագիրը կարող է տարբերակել «սփամ» և «սովորական» նամակները՝ տվյալների հիման վրա։

---

##  Ֆայլերի կառուցվածքը

```bash
 spam-detector/
├── include/
│   ├── TfidfVectorizer.h
│   ├── LogisticRegression.h
│   └── DataLoader.h
├── src/
│   ├── main.cpp
├── mail_data.csv
├── README.md
```

---

##  Օգտագործվող Ալգորիթմներ

### 1. **TF-IDF** (Term Frequency - Inverse Document Frequency)
- Թվային կերպ է ներկայացնում բառերը՝ հաշվի առնելով հաճախականությունը և եզակիությունը։

### 2. **Logistic Regression**
- Դասակարգիչ մոդել է, որը սովորում է `spam` և `ham` պիտակների հիման վրա։

---


###  **TF-IDF** (Term Frequency - Inverse Document Frequency)

**TF-IDF**-ը մեկական բառերի կարևորությունը որոշելու մեթոդ է՝ հաշվի առնելով այն, թե որքան հաճախ են դրանք հանդիպում տեքստում և որքան տարածված են դրանք մյուս փաստաթղթերում:

#### 1. **Term Frequency (TF)**

Term Frequency-ն (TF) ցույց է տալիս, թե որքան հաճախ է մեկ բառը հայտնվում որոշակի փաստաթղթում: Այն հաշվարկվում է հետևյալ կերպ.

![image](https://github.com/user-attachments/assets/98b2505a-6a73-4d7d-ba5f-9ebc2275fb5a)

#### 2. **Inverse Document Frequency (IDF)**

IDF-ն ցույց է տալիս, թե որքան կարևոր է բառը բոլոր փաստաթղթերի համեմատ։ Այն հաշվի է առնում, թե որքան քիչ է հանդիպում այդ բառը ամբողջ փաստաթղթերի մեջ։ Որքան ավելի քիչ է հանդիպում բառը այլ փաստաթղթերում, այնքան ավելի մեծ է նրա արժեքը:

IDF հաշվարկվում է հետևյալ կերպ.

\[
\text{IDF}(t, D) = \log\left(\frac{|D|}{1 + \text{Document Frequency}(t)}\right)
\]

Որտեղ `|D|` բոլոր փաստաթղթերի քանակն է, իսկ `Document Frequency(t)`-ն ցույց է տալիս, թե որքան փաստաթղթերում է հանդիպում տվյալ բառը:

#### 3. **TF-IDF**

Հաշվարկվում է TF և IDF-ի գումարով.

\[
\text{TF-IDF}(t, d, D) = \text{TF}(t, d) \times \text{IDF}(t, D)
\]

Այսպիսով, **TF-IDF**-ը տալիս է յուրաքանչյուր բառի կարևորությունը՝ հաշվի առնելով թե քանի անգամ է բառը հանդիպում տվյալ փաստաթղթում, նաև որքան հազվադեպ է այն հանդիպում մյուս փաստաթղթերում:

---

###  **Լոգիստիկ Ռեգրեսիա (Logistic Regression)**

Լոգիստիկ ռեգրեսիան մաթեմատիկական մոդել է, որն օգտագործվում է երկու դասերի (օրինակ՝ `spam` և `ham`) միջև տարբերություն հաստատելու համար։ Այն հիմնված է **լոգիստիկ ֆունկցիայի** վրա՝ որը կանխատեսում է այն հավանականությունը, որ տրված փաստաթուղթը համապատասխանում է կոնկրետ կլասսի

#### 1. **Լոգիստիկ Ֆունկցիա**

Լոգիստիկ ֆունկցիան հետևյալ տեսքն ունի:

\[
P(y = 1 | X) = \frac{1}{1 + e^{-z}}
\]

Որտեղ՝  
- \( P(y = 1 | X) \) ՝ հիպոթեզի հավանականությունն է, որ տրված փաստաթուղթը կլինի `spam`։  
- \( z \)՝ գրադիենտի և կշռերի պարամետրերի միավորն է, որը հաշվում է հետևյալ կերպ՝  
  \[
  z = b + \sum_{i=1}^{n} w_i x_i
  \]  
  որտեղ `b`-ն բայասն է, \( w_i \)-ները կշիռներն են, իսկ \( x_i \)-ները՝ տվյալ վեկտորի բաղադրիչները։

#### 2. **Կորստի ֆունկցիա (Loss Function)**

Մոդելը սովորում է նվազագույն կորստի ֆունկցիային՝ օգտագործելով **լոգիստիկ ռեգրեսիայի** կորսգտի ֆունկցիան, որը հաճախ կոչվում է **խաչաձև ռիսկի կորսի (cross-entropy loss)**։

\[
\text{Loss}(y, \hat{y}) = - \left( y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right)
\]

Որտեղ՝  
- \( y \)՝ իրական պիտակն է (spam կամ ham)։
- \( \hat{y} \)՝ մոդելի կանխատեսված հավանականությունն է։

#### 3. **Gradient Descent**

Լոգիստիկ ռեգրեսիան սովորում է **Gradient Descent** մեթոդով՝ նպատակ ունենալով նվազագույնի հասցնել կորստի ֆունկցիան՝ յուրաքանչյուր պարբերությունում թարմացնելով կշիռները (weights)։

Կշիռների թարմացումը կատարում է հետևյալ կերպ.

\[
w_i := w_i - \alpha \frac{\partial \text{Loss}}{\partial w_i}
\]
\[
b := b - \alpha \frac{\partial \text{Loss}}{\partial b}
\]

Որտեղ՝  
- \( \alpha \)՝ ուսուցման արագությունն է (learning rate)։
- \( \frac{\partial \text{Loss}}{\partial w_i} \)՝ կորսի ֆունկցիայի պարբերական ածանցը \( w_i \)-ի նկատմամբ։

---

### **Կոդի Պատմություն**

1. **Տվյալների վերլուծություն (Preprocessing)**:  
   - Քաղվում են նամակների բառերը, նրանց հաճախականությունները հաշվում են, ապա հաշվարկվում են TF-IDF արժեքները։
  
2. **Մոդելի ուսուցում**:  
   - Մոդելն օգտագործում է լոգիստիկ ռեգրեսիա՝ ամեն մուտքային նամակի համար հիպոթեզի պիտակը հաշվարկելու համար։

3. **Կապակցված տվյալներ**:  
   - Քանի որ TF-IDF հաշվարկված է հենց բառերի հիանալի ներկայացման վրա, այն օգտագործվում է որպես մուտքային տվյալներ լոգիստիկ ռեգրեսիային։

---

###  Նկարագրություններ

#### 1. **TF-IDF- ի բառակապակցություններ**

```plaintext
      Words    --->   Frequency Calculation  --->   Term Frequency
        |                                 |
        v                                 v
    Document Count       --->    Inverse Document Frequency
        |                                 |
        v                                 v
      TF-IDF Calculation
```

#### 2. **Լոգիստիկ Ռեգրեսիայի Ուսուցում**

```plaintext
    Data Preprocessing
            |
            v
    Feature Vectorization  --->   Model Training  --->   Prediction
                                  (Logistic Regression)
            |
            v
        Evaluation
```

---

Այս նկարագրությունները ու մաթեմատիկական բացատրությունները պետք է ավելի լավ պատկերացնեն TF-IDF-ի և լոգիստիկ ռեգրեսիայի հաշվարկային մեթոդները։

##  C++ Կոդի Նկարագրություն

 Իմպլեմենտացված են **ձեռքով** հետևյալ դասերը.

- `TfidfVectorizer`: Վերլուծում է տեքստը, հաշվում է բառերի հաճախականությունը, հաշվարկում է TF-IDF արժեքները։
- `LogisticRegression`: Իրականացնում է train / predict մեթոդներ՝ լոգիստիկ ֆունկցիայով։

Օգտագործում է STL (`map`, `vector`, `string`, `cmath`)։  
Վերբեռնում է CSV ֆայլ, բաժանում train/test, ցուցադրում ճշգրտությունը։

```cpp
Accuracy: 0.9375
Prediction for new message: 1
```

---

##  Python Կոդի Նկարագրություն

 Իրականացվում է Google Colab-ում՝ օգտագործելով հետևյալ գրադարանները.

- `pandas`: CSV ֆայլերի համար
- `sklearn.feature_extraction.text.TfidfVectorizer`: Վեկտորիզացիայի համար
- `sklearn.linear_model.LogisticRegression`: Մոդելի ուսուցում
- `sklearn.model_selection.train_test_split`, `accuracy_score`

 Ավելի կոմպակտ է, սակայն կախված է արտաքին գրադարաններից։

```python
Accuracy: 0.9375
```

---

##  C++ և Python Համեմատություն

| Նկարագրություն        | C++                                     | Python                                        |
|----------------------|------------------------------------------|-----------------------------------------------|
| Տիպը                 | Ստորին մակարդակի                         | Բարձր մակարդակի                               |
| Գործառույթներ        | Ձեռքով իրագործված                        | Գրադարաններով                                 |
| Արտաքին գրադարաններ | Չկան                                     | Scikit-learn, pandas                          |
| Արագություն          | Ավելի բարձր                              | Ավելի դանդաղ                                   |
| Կոդի ծավալ           | Ավելի երկար                              | Ավելի համառոտ                                 |
| Ավելի հարմար         | Մշակման, ուսուցման և deployment-ի համար   | Փորձարկման և մոդելավորման համար                |

---

##  Մուտքային Տվյալների Ֆորմատ

### `mail_data.csv`
```csv
Category,Message
spam,You have won a free ticket!
ham,Hello, how are you today?
spam,Click here to claim your prize
```

---




###  Ծրագրի Workflow (Տվյալների նախապատրաստում և մոդելավորման հոսք)

```plaintext
[CSV File]
    |
    v
[Data Preprocessing (Cleaning & Splitting)]
    |
    v
[TF-IDF Vectorization]
    |
    v
[Logistic Regression Model]
    |
    v
[Prediction & Evaluation]
```





 Ներկայացվել է որպես կուրսային նախագիծ  
 Ստեղծվել է ՀԱՊՀ ՏՏ 219 Խմբի 3-րդ կուրսի ուսանողուհի էլիզա Մարտիրոսյանի կողմից


